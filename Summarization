{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyM98AmOcHhk2chKMiWyKUTN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b6f481068d6241d084097b1d3d9240e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e14fb3e2c5b24ff793a2ff2c25a72baf","IPY_MODEL_3815a3b72b504fc2919cc3b14b487147","IPY_MODEL_d65ef61371254f4fb03ca6417486124a"],"layout":"IPY_MODEL_9d330b9de773422ea273640d623a4ed1"}},"e14fb3e2c5b24ff793a2ff2c25a72baf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ae92bcd3804d199b9ff680d996dcc8","placeholder":"​","style":"IPY_MODEL_a9507e1e241941b5916ddee65ed85f6c","value":"Downloading builder script: "}},"3815a3b72b504fc2919cc3b14b487147":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_556f34680af44d7282a730f73b8a60dc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_606ca3bbd0564d2ea50c94bd615ed9ad","value":1}},"d65ef61371254f4fb03ca6417486124a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89596732ff064d62af86c4a700aed1dc","placeholder":"​","style":"IPY_MODEL_8250b43422c640f79088ee0b73c87720","value":" 6.27k/? [00:00&lt;00:00, 636kB/s]"}},"9d330b9de773422ea273640d623a4ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ae92bcd3804d199b9ff680d996dcc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9507e1e241941b5916ddee65ed85f6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"556f34680af44d7282a730f73b8a60dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"606ca3bbd0564d2ea50c94bd615ed9ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89596732ff064d62af86c4a700aed1dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8250b43422c640f79088ee0b73c87720":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12369a286f7a4aff8a35038576827027":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06377941be9e41f6be4adad5e620bc36","IPY_MODEL_ea8a1e65515c44b3aa7a8b8983668fae","IPY_MODEL_1145df3111d44b1cba52490fd9bbcd20"],"layout":"IPY_MODEL_caabd0a1f8dd44da9ea4b32db453e09d"}},"06377941be9e41f6be4adad5e620bc36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d07e4086e4a84d91a18aa5920cec4e80","placeholder":"​","style":"IPY_MODEL_4049798c10164b07ab2dad9146cab422","value":"Downloading builder script: "}},"ea8a1e65515c44b3aa7a8b8983668fae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09a13d1f2b2c4ec0b4ffefc09933c478","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c1dded9b2e34c8e825eb837854bdd06","value":1}},"1145df3111d44b1cba52490fd9bbcd20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd0c00ee85604abfa04f8638cc6da1bb","placeholder":"​","style":"IPY_MODEL_ed1dc0aa86974ba98071ce3b872bce21","value":" 7.95k/? [00:00&lt;00:00, 896kB/s]"}},"caabd0a1f8dd44da9ea4b32db453e09d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d07e4086e4a84d91a18aa5920cec4e80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4049798c10164b07ab2dad9146cab422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09a13d1f2b2c4ec0b4ffefc09933c478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9c1dded9b2e34c8e825eb837854bdd06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd0c00ee85604abfa04f8638cc6da1bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed1dc0aa86974ba98071ce3b872bce21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d97224802f2646e3ab32f0fdc757d961":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ffbebbbace74953901996aaf1d697ba","IPY_MODEL_4549596c9aa8494cbb877afdc3ff3bdf","IPY_MODEL_14f2a20b8a494333b98b6c3dec498447"],"layout":"IPY_MODEL_8d50f94cce734cbcba73ba84d4243a13"}},"4ffbebbbace74953901996aaf1d697ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91b03e2747a6462a975f6acc189cc78d","placeholder":"​","style":"IPY_MODEL_25a5c5f5d97148cbbf3d524cceec37ab","value":"Local Generation: 100%"}},"4549596c9aa8494cbb877afdc3ff3bdf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b69a6c67a874d66b9e60a4e25bed4fc","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2b759b054db46bbbb7521e72b998808","value":100}},"14f2a20b8a494333b98b6c3dec498447":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9118c2a6d24c4aaabc5f4f930060c0","placeholder":"​","style":"IPY_MODEL_66355031fa1242c784335217a68695b1","value":" 100/100 [06:52&lt;00:00,  4.28s/it]"}},"8d50f94cce734cbcba73ba84d4243a13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"91b03e2747a6462a975f6acc189cc78d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a5c5f5d97148cbbf3d524cceec37ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b69a6c67a874d66b9e60a4e25bed4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b759b054db46bbbb7521e72b998808":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c9118c2a6d24c4aaabc5f4f930060c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66355031fa1242c784335217a68695b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf36f36134924d67a9c9a15f7a0ee15d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2b15b2e097e48e88b787066a354f9c1","IPY_MODEL_c91459c8e10f4793bc13e0d6e7620d45","IPY_MODEL_114366612a464057ad1893c43216f686"],"layout":"IPY_MODEL_aa2f6649bffa46918873b8b130fd22e5"}},"e2b15b2e097e48e88b787066a354f9c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12690f5ddbc941d0b8f5ed17fcf337a8","placeholder":"​","style":"IPY_MODEL_0db487735afb4c29aaf7522cb34defd8","value":"Local Generation: 100%"}},"c91459c8e10f4793bc13e0d6e7620d45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c34ab5699464fc59860d26f2fdedd8b","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c94d0c0be9747ca8881340116459273","value":100}},"114366612a464057ad1893c43216f686":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af0d9fe7f324d42bd2525a363adea3a","placeholder":"​","style":"IPY_MODEL_cf6ecadec82f48f1b6ca4f43efc64101","value":" 100/100 [09:14&lt;00:00,  5.21s/it]"}},"aa2f6649bffa46918873b8b130fd22e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"12690f5ddbc941d0b8f5ed17fcf337a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db487735afb4c29aaf7522cb34defd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c34ab5699464fc59860d26f2fdedd8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c94d0c0be9747ca8881340116459273":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9af0d9fe7f324d42bd2525a363adea3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6ecadec82f48f1b6ca4f43efc64101":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80b757ec8a95404eb644981847c4e4ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4cefe4c35844e4fb4915c8dab09fa4e","IPY_MODEL_e9859c2a953b479d98f97c54da2c499a","IPY_MODEL_77a30748d1db42d49acba426b58f1efe"],"layout":"IPY_MODEL_5665ef0fb79342ceaf0ca207aaa390b1"}},"f4cefe4c35844e4fb4915c8dab09fa4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebf8642ab1bc4fb886801b331fa95130","placeholder":"​","style":"IPY_MODEL_ddcba0896f5f41de9046cb071d293956","value":"Map: 100%"}},"e9859c2a953b479d98f97c54da2c499a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9b72c899ca4b4b98b97a20eb980ad7","max":1336,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21d2966dcd4b4611b5ba272a32f1f502","value":1336}},"77a30748d1db42d49acba426b58f1efe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c986f9f4aba411f86328acbd0b56f6a","placeholder":"​","style":"IPY_MODEL_02ca70270a57402c82a0e5f96e7e767a","value":" 1336/1336 [00:00&lt;00:00, 4366.77 examples/s]"}},"5665ef0fb79342ceaf0ca207aaa390b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebf8642ab1bc4fb886801b331fa95130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddcba0896f5f41de9046cb071d293956":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d9b72c899ca4b4b98b97a20eb980ad7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d2966dcd4b4611b5ba272a32f1f502":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c986f9f4aba411f86328acbd0b56f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02ca70270a57402c82a0e5f96e7e767a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJhPdQdVrGB8","executionInfo":{"status":"ok","timestamp":1752968851837,"user_tz":300,"elapsed":18266,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"3890149c-61a1-4707-ff9b-0f3caf607f55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","The `introdl` module is already installed.\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set project path\n","project_path = '/content/drive/MyDrive/CAPSTONE'\n","\n","import sys\n","sys.path.append(f'{project_path}/scripts')\n","from pathlib import Path\n","\n","# Point to the correct folder in Drive\n","course_tools_path = Path('/content/drive/MyDrive/CAPSTONE')\n","sys.path.append(str(course_tools_path))\n","\n","# Import and run the installer\n","from install_introdl import ensure_introdl_installed\n","ensure_introdl_installed(force_update=False, local_path_pkg=course_tools_path / 'introdl')"]},{"cell_type":"code","source":["!pip install bitsandbytes accelerate\n","!pip install torchinfo\n","!pip install evaluate\n","!pip install rouge_score\n","!pip install bert_score\n","!pip install rapidfuzz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9gAXGQgyp1P","executionInfo":{"status":"ok","timestamp":1752968965170,"user_tz":300,"elapsed":106954,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"6c4fdc39-62bf-42de-bc17-9b295a362b80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n","Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","Collecting evaluate\n","  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.5\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=5ce1f1f1508cceac1a234942bccd666ba41eb9bf431dc554154c127f923fd56c\n","  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","Collecting bert_score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.53.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.33.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.7.14)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bert_score\n","Successfully installed bert_score-0.3.13\n","Collecting rapidfuzz\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz\n","Successfully installed rapidfuzz-3.13.0\n"]}]},{"cell_type":"code","source":["from introdl.utils import config_paths_keys, wrap_print_text\n","\n","# call cnonfig_paths_keys() before importing hugging face packages\n","paths = config_paths_keys()\n","MODELS_PATH = paths['MODELS_PATH'] # where to store your trained models\n","DATA_PATH = paths['DATA_PATH'] # where to store downloaded data\n","#CACHE_PATH = paths['CACHE_PATH'] # where to store pretrained models\n","\n","print = wrap_print_text(print, width = 100)\n","\n","from datasets import load_dataset\n","from evaluate import load\n","from nltk import sent_tokenize, download\n","import numpy as np\n","import torch\n","import transformers\n","import pandas as pd\n","from transformers import (\n","    Trainer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM,\n","    AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",")\n","import warnings\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n","from transformers import DataCollatorWithPadding\n","from transformers import TrainingArguments, Trainer\n","import torch\n","\n","# Download Punkt tokenizer for sentence splitting (used by ROUGE-Lsum)\n","download(\"punkt\", quiet=True)\n","download(\"punkt_tab\", quiet=True)\n","\n","# Load evaluation metrics\n","rouge = load(\"rouge\")\n","bertscore = load(\"bertscore\")\n","\n","# Suppress warnings from the transformers library\n","transformers.logging.set_verbosity_error()\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","def compute_all_metrics(y_true, y_pred, labels=None):\n","    acc = accuracy_score(y_true, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=labels, average='weighted')\n","    return {\n","        \"accuracy\": acc,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }\n","\n","from introdl.nlp import llm_configure, llm_generate, llm_list_models\n","\n","from IPython.display import display, HTML, clear_output, Markdown\n","import gc # for memory management\n","import pandas as pd\n","from openai import OpenAI\n","import openai\n","import os\n","import re\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","from introdl.utils import config_paths_keys, wrap_print_text\n","print = wrap_print_text(print, width = 100)\n","\n","from introdl.utils import config_paths_keys\n","\n","path = config_paths_keys() # this loads the keys and path variables.\n","\n","MODELS_PATH = paths['MODELS_PATH']\n","DATA_PATH = paths['DATA_PATH']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466,"referenced_widgets":["b6f481068d6241d084097b1d3d9240e8","e14fb3e2c5b24ff793a2ff2c25a72baf","3815a3b72b504fc2919cc3b14b487147","d65ef61371254f4fb03ca6417486124a","9d330b9de773422ea273640d623a4ed1","99ae92bcd3804d199b9ff680d996dcc8","a9507e1e241941b5916ddee65ed85f6c","556f34680af44d7282a730f73b8a60dc","606ca3bbd0564d2ea50c94bd615ed9ad","89596732ff064d62af86c4a700aed1dc","8250b43422c640f79088ee0b73c87720","12369a286f7a4aff8a35038576827027","06377941be9e41f6be4adad5e620bc36","ea8a1e65515c44b3aa7a8b8983668fae","1145df3111d44b1cba52490fd9bbcd20","caabd0a1f8dd44da9ea4b32db453e09d","d07e4086e4a84d91a18aa5920cec4e80","4049798c10164b07ab2dad9146cab422","09a13d1f2b2c4ec0b4ffefc09933c478","9c1dded9b2e34c8e825eb837854bdd06","bd0c00ee85604abfa04f8638cc6da1bb","ed1dc0aa86974ba98071ce3b872bce21"]},"id":"XNS-iRFkt8Sf","executionInfo":{"status":"ok","timestamp":1752968991672,"user_tz":300,"elapsed":26498,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"e2ed533f-416f-4030-e567-1cad7f6ed3b6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["MODELS_PATH=.\n","DATA_PATH=.\n","TORCH_HOME=.\n","HF_HOME=.\n","HF_HUB_CACHE=.\n","Set HF_TOKEN in api_keys.env or in environment to login to HuggingFace Hub\n","Most things should work without logging in, but some features may be limited.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6f481068d6241d084097b1d3d9240e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12369a286f7a4aff8a35038576827027"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MODELS_PATH=.\n","DATA_PATH=.\n","TORCH_HOME=.\n","HF_HOME=.\n","HF_HUB_CACHE=.\n","Set HF_TOKEN in api_keys.env or in environment to login to HuggingFace Hub\n","Most things should work without logging in, but some features may be limited.\n"]}]},{"cell_type":"code","source":["# ✅ Clear GPU memory before evaluation\n","import torch\n","torch.cuda.empty_cache()\n","\n","LLM_MODEL = 'unsloth/mistral-7b-instruct-v0.3-bnb-4bit'\n","llm_config = llm_configure(LLM_MODEL)\n","\n","def llm_summarizer(llm_config, conversations, system_prompt, prompt_template, batch_size=1, estimate_cost=False, rate_limit=None):\n","    \"\"\"\n","    Summarize conversations using a Large Language Model (LLM).\n","\n","    Args:\n","        llm_config (ModelConfig): Configuration for the LLM.\n","        conversations (list of str): List of conversation transcripts to summarize.\n","        system_prompt (str): System prompt to guide the LLM.\n","        prompt_template (str): Template for user prompts to summarize each conversation.\n","        batch_size (int): Number of conversations to process in a batch for local models.\n","        estimate_cost (bool): Whether to estimate the cost of the LLM request for API models.\n","        rate_limit (int): Rate limit per minute for API requests to avoid overloading the LLM service.\n","\n","    Returns:\n","        list of str: Summaries for the input conversations.\n","    \"\"\"\n","    user_prompts = [prompt_template.format(conversation=conversation) for conversation in conversations]\n","    summaries = llm_generate(llm_config,\n","                             user_prompts,\n","                             system_prompt=system_prompt,\n","                             search_strategy='deterministic',\n","                             batch_size=batch_size,\n","                             estimate_cost=estimate_cost,\n","                             rate_limit=rate_limit)\n","    return summaries\n","\n","import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/CAPSTONE/data/Hyatt_LTR_Sentiment.csv')\n","df = df[['Additional.Feedback.on.Overall.Stay', 'Sentiment']].dropna()\n","#df = pd.DataFrame(dataset['train'])\n","\n","# Downsample the dataset if needed\n","downsample_ratio = 1.0\n","if downsample_ratio < 1.0:\n","    df = df.sample(int(downsample_ratio * df.shape[0]))\n","    print(f'Downsampled dataset has {df.shape[0]} conversations')\n","\n","# Split data into train and test sets\n","train_texts_str, test_texts_str, train_summaries_str, test_summaries_str = train_test_split(\n","    df[\"Additional.Feedback.on.Overall.Stay\"].tolist(),\n","    df[\"Sentiment\"].tolist(),\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","\n","N = 100\n","texts = test_texts_str[0:N]\n","summaries = test_summaries_str[0:N]\n","\n","system_prompt = \"\"\"You are an expert at summarizing conversations. Your task is to generate a very short and concise summaries of the provided conversations\"\"\"\n","prompt_template = \"\"\"\n","Summarize the following conversation in one to two sentences:\n","{conversation}\n","Summary:\n","\n","\"\"\"\n","generated_summaries = llm_summarizer(llm_config, texts, system_prompt, prompt_template, batch_size=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d97224802f2646e3ab32f0fdc757d961","4ffbebbbace74953901996aaf1d697ba","4549596c9aa8494cbb877afdc3ff3bdf","14f2a20b8a494333b98b6c3dec498447","8d50f94cce734cbcba73ba84d4243a13","91b03e2747a6462a975f6acc189cc78d","25a5c5f5d97148cbbf3d524cceec37ab","0b69a6c67a874d66b9e60a4e25bed4fc","b2b759b054db46bbbb7521e72b998808","7c9118c2a6d24c4aaabc5f4f930060c0","66355031fa1242c784335217a68695b1"]},"id":"OHzBTFDizptb","executionInfo":{"status":"ok","timestamp":1752970577345,"user_tz":300,"elapsed":412690,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"e8853fad-1876-4583-f20f-8b81875127f1"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["Local Generation:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97224802f2646e3ab32f0fdc757d961"}},"metadata":{}}]},{"cell_type":"code","source":["# Print the first 5 generated summaries and their ground-truth summaries\n","for i in range(5):\n","    print(f\"Original Feedback: {test_texts_str[i]}\")\n","    print(f\"Model-Generated Summary: {generated_summaries[i]}\")\n","    print(f\"Labeled Sentiment: {test_summaries_str[i]}\")\n","    print(\"-\" * 100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgYbtQ_m3Cap","executionInfo":{"status":"ok","timestamp":1752970879478,"user_tz":300,"elapsed":8,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"898a6c01-efaa-4970-8fa2-914fa9ec0173"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Feedback: Room was very dated.  Definitely did not meet the expectations I have for a Hyatt\n","property.   Lobby area was nice but rooms were very dated and appeared dirty.   We would not even\n","sit on the couch in the room.\n","Model-Generated Summary: The guest found the Hyatt property's rooms outdated, unclean, and below\n","their expected standards; they avoided using furniture like the couch due to its condition.\n","Labeled Sentiment: Negative\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: Had a wonderful stay and would be happy to stay longer if I ever need to.  The\n","facility does show some wear here and there, nothing major or worth specifically calling out.\n","Overall everything for my stay was great\n","Model-Generated Summary: Guest had a positive experience with minor cosmetic issues at the facility;\n","they'd return due to overall satisfaction.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: I'd definitely like to keep booking the same type of room going forward\n","Model-Generated Summary: The user prefers to continue reserving the same room type for future\n","bookings.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: My fiancé and I booked the Hyatt in Green Bay, WI, because we had previously\n","stayed at a Hyatt in Chicago, IL-- and loved it. We are very displeased with our stay in at the\n","Hyatt, in WI, and will not be returning.\n","Here are a few things, which have steered our stay to other locations moving forward.\n","1. The room was not clean. We arrived and paid for early check in-- yet got put in a room that had\n","dust all over the place.\n","2. The tv had a burn mark.\n","3. The carpet had a wrinkle in it, between the sliding door and bed, causing me to trip in the\n","middle of the night.\n","4. Went to look in the brochure to find the floor in which the laundry room was, and the brochure\n","appeared to be half eaten by an animal-- therefore we had to call the lobby for them to tell us,\n","what we should have been able to know without calling. That's the whole point of a brochure in a\n","guest room. Very inconvenient.\n","5. The view that we had was horrendous. Opening our curtains, to find we had a beautiful view of the\n","AC units.\n","6. We paid extra for the morning breakfast. Upon arrival, there was no host. We asked a server and\n","she said \"seat yourself, and someone will come get your drinks.\" We did just that. And 10 minutes\n","went by. We had to get up not just once, but twice to get our drinks. That is terrible service and\n","very  unacceptable.\n","\n","Like stated above, we will not be returning to the Hyatt Hotels. The many inconveniences and awful\n","service in the dining area, have made up our mind, that we will in fact take our money elsewhere and\n","stay where we feel we are appreciated.\n","\n","Thank you,\n","\n","Dillon Jones\n","Model-Generated Summary: Dillon Jones expresses dissatisfaction with their stay at the Hyatt Hotel\n","in Green Bay, WI due to multiple issues including a dirty room, damaged TV and carpet, poor\n","information availability, unsightly view, and subpar service during breakfast. As a result, they\n","will not return to Hyatt Hotels and plan to spend future stays elsewhere.\n","Labeled Sentiment: Very Negative\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: Quality of service was good, but there is always a room for improvement. A smile\n","on their face and saying good morning and good afternoon when ever people approach them it will make\n","it more personal for people to come back an stay at your facility.\n","Model-Generated Summary: Service quality is satisfactory with potential enhancements; fostering\n","personal connections through friendly greetings may encourage repeat visits.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["LLM_MODEL = 'unsloth/mistral-7b-instruct-v0.3-bnb-4bit'\n","llm_config = llm_configure(LLM_MODEL)\n","\n","def llm_summarizer(llm_config,\n","                   conversations,\n","                   system_prompt,\n","                   prompt_template,\n","                   batch_size=1,\n","                   estimate_cost=False,\n","                   rate_limit=None):\n","    \"\"\"\n","    Summarize conversations using a Large Language Model (LLM).\n","\n","    Args:\n","        llm_config (ModelConfig): Configuration for the LLM.\n","        conversations (list of str): List of conversation transcripts to summarize.\n","        system_prompt (str): System prompt to guide the LLM.\n","        prompt_template (str): Template for user prompts to summarize each conversation.\n","        batch_size (int): Number of conversations to process in a batch for local models.\n","        estimate_cost (bool): Whether to estimate the cost of the LLM request for API models.\n","        rate_limit (int): Rate limit per minute for API requests to avoid overloading the LLM service.\n","\n","    Returns:\n","        list of str: Summaries for the input conversations.\n","    \"\"\"\n","\n","    user_prompts = [prompt_template.format(conversation=conversation) for conversation in conversations]\n","    summaries = llm_generate(llm_config,\n","                             user_prompts,\n","                             system_prompt=system_prompt,\n","                             search_strategy='deterministic',\n","                             batch_size=batch_size,\n","                             estimate_cost=estimate_cost,\n","                             rate_limit=rate_limit)\n","\n","    return summaries\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/CAPSTONE/data/Hyatt_LTR_Sentiment.csv')\n","df = df[['Additional.Feedback.on.Overall.Stay', 'Sentiment']].dropna()\n","#df = pd.DataFrame(dataset['train'])\n","\n","# Downsample the dataset if needed\n","downsample_ratio = 1.0\n","if downsample_ratio < 1.0:\n","    df = df.sample(int(downsample_ratio * df.shape[0]))\n","    print(f'Downsampled dataset has {df.shape[0]} conversations')\n","\n","# Split data into train and test sets\n","train_texts_str, test_texts_str, train_summaries_str, test_summaries_str = train_test_split(\n","    df[\"Additional.Feedback.on.Overall.Stay\"].tolist(), df[\"Sentiment\"].tolist(), test_size=0.2, random_state=42\n",")\n","\n","N = 100\n","texts = test_texts_str[0:N]\n","summaries = test_summaries_str[0:N]\n","\n","# Select diverse and challenging examples\n","few_shot_examples = [\n","    {\n","        \"conversation1\": \"Sarah: I found a song on youtube and I think you'll like it\\nJames: What song?\\nSarah: <file_other>\\nJames: Oh. I know it!\\nJames: I heard it before in some compilation\\nSarah: I can't stop playing it over and over\\nJames: That's exactly how I know lyrics to all of the songs on my playlist :D\\nSarah: Haha. No lyrics here though. Instrumental ;D\\nJames: Instrumental songs are different kind of music.\\nJames: But you have to remember that the activity you do when you listen to this song\\nJames: Is the actvity your brain will connect to the song\\nJames: And everytime you play this song at home\\nJames: You'll be thinking of your work\\nSarah: Yeah, I know that. That's why we sometimes say - I used to like that song, but now it just reminds me of bad memories\\nJames: Yup. Everytime you change your partner, you have to get rid of your favorite music :D\\nSarah: Hahaha. True, true.\",\n","        \"summary\": \"Sarah sends James an instrumental song he might like. James knows the song. The brain connects the songs to the context they were played in and brings to mind the associated memories.\"\n","    },\n","    {\n","        \"conversation2\": \"Veronica: Hi, just got back home and I saw that new sofa you bought\\nFrank: And? Do you like it?\\nVeronica: Pity you didn't send me a picture before buying it...\\nFrank: Is it that bad?\\nVeronica: Do you really think it's nice?\\nFrank: Well, I like it\\nVeronica: Ok, but it doesn't necessarily go well with the rest of the stuff inside\\nFrank: Eh, I don't think it's that bad.\\nFrank: Can we talk about it when I'm back? Got a lot of work\\nVeronica: Ok, sure. Although I hope you kept the receipt\",\n","        \"summary\": \"Frank bought a sofa. Veronica doesn't like it. They will talk about it when he's back.\"\n","    },\n","    {\n","        \"conversation3\": \"Emily: I reckon i need a new hobby or i'll keep baking and getting fat! x\\nRose: oh no! i love your baking!\\nKevin: let me know when you're baking next time!\\nDonna: from what i see you're very creative so think about some other creative stuff\\nHolly: something like painting or renovating old furniture\\nBen: try sewing clothes, handmade jewellery\\nEmily: i didn't think about my baking that way?! like the ideas\\nBen: there are so many ways you can be creative in and express yourself\\nEmily: thanks guys! xxx.\",\n","        \"summary\": \"Emily is looking for a creative hobby to replace baking.\"\n","    }\n","]\n","\n","\n","system_prompt2 = \"\"\"\n","You are a conversation summarizer. Your task is to summarize conversations concisely and accurately. Here are some examples:\n","\n","Example 1:\n","Conversation: Sarah: I found a song on youtube and I think you'll like it\\nJames: What song?\\nSarah: <file_other>\\nJames: Oh. I know it!\\nJames: I heard it before in some compilation\\nSarah: I can't stop playing it over and over\\nJames: That's exactly how I know lyrics to all of the songs on my playlist :D\\nSarah: Haha. No lyrics here though. Instrumental ;D\\nJames: Instrumental songs are different kind of music.\\nJames: But you have to remember that the activity you do when you listen to this song\\nJames: Is the actvity your brain will connect to the song\\nJames: And everytime you play this song at home\\nJames: You'll be thinking of your work\\nSarah: Yeah, I know that. That's why we sometimes say - I used to like that song, but now it just reminds me of bad memories\\nJames: Yup. Everytime you change your partner, you have to get rid of your favorite music :D\\nSarah: Hahaha. True, true.\n","Summary: Sarah sends James an instrumental song he might like. James knows the song. The brain connects the songs to the context they were played in and brings to mind the associated memories.\n","\n","Example 2:\n","Conversation: Veronica: Hi, just got back home and I saw that new sofa you bought\\nFrank: And? Do you like it?\\nVeronica: Pity you didn't send me a picture before buying it...\\nFrank: Is it that bad?\\nVeronica: Do you really think it's nice?\\nFrank: Well, I like it\\nVeronica: Ok, but it doesn't necessarily go well with the rest of the stuff inside\\nFrank: Eh, I don't think it's that bad.\\nFrank: Can we talk about it when I'm back? Got a lot of work\\nVeronica: Ok, sure. Although I hope you kept the receipt\n","Summary: Frank bought a sofa. Veronica doesn't like it. They will talk about it when he's back.\n","\n","Example 3:\n","Conversation: Emily: I reckon i need a new hobby or i'll keep baking and getting fat! x\\nRose: oh no! i love your baking!\\nKevin: let me know when you're baking next time!\\nDonna: from what i see you're very creative so think about some other creative stuff\\nHolly: something like painting or renovating old furniture\\nBen: try sewing clothes, handmade jewellery\\nEmily: i didn't think about my baking that way?! like the ideas\\nBen: there are so many ways you can be creative in and express yourself\\nEmily: thanks guys! xxx.\n","Summary: Emily is looking for a creative hobby to replace baking.\n","\n","Now, summarize the following conversation:\n","{conversation}\n","\"\"\"\n","\n","prompt_template = \"\"\"\n","Conversation:\n","{conversation}\n","\n","Summary:\n","\"\"\"\n","generated_summaries2 = llm_summarizer(llm_config, texts, system_prompt2, prompt_template, batch_size=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cf36f36134924d67a9c9a15f7a0ee15d","e2b15b2e097e48e88b787066a354f9c1","c91459c8e10f4793bc13e0d6e7620d45","114366612a464057ad1893c43216f686","aa2f6649bffa46918873b8b130fd22e5","12690f5ddbc941d0b8f5ed17fcf337a8","0db487735afb4c29aaf7522cb34defd8","5c34ab5699464fc59860d26f2fdedd8b","0c94d0c0be9747ca8881340116459273","9af0d9fe7f324d42bd2525a363adea3a","cf6ecadec82f48f1b6ca4f43efc64101"]},"id":"vKgE4zOB41wQ","executionInfo":{"status":"ok","timestamp":1752971505440,"user_tz":300,"elapsed":554577,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"8a2890b5-7411-43fc-c22e-457dcf5ab0ac"},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":["Local Generation:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf36f36134924d67a9c9a15f7a0ee15d"}},"metadata":{}}]},{"cell_type":"code","source":["import json\n","\n","# Save to JSON\n","with open(\"generated_summaries_llm.json\", \"w\") as f:\n","    json.dump(generated_summaries2, f)\n","\n","print(\"✅ Summaries saved to generated_summaries_llm.json\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twj3_Ea4Sf8w","executionInfo":{"status":"ok","timestamp":1752971514144,"user_tz":300,"elapsed":9,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"3aff8b0a-10c8-4e87-e6e5-1c1b486c4273"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Summaries saved to generated_summaries_llm.json\n"]}]},{"cell_type":"code","source":["# Print the first 5 generated summaries and their ground-truth summaries\n","for i in range(5):\n","    print(f\"Original Feedback: {test_texts_str[i]}\")\n","    print(f\"Model-Generated Summary: {generated_summaries2[i]}\")\n","    print(f\"Labeled Sentiment: {test_summaries_str[i]}\")\n","    print(\"-\" * 100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZpHsenc5A9f","executionInfo":{"status":"ok","timestamp":1752971519136,"user_tz":300,"elapsed":12,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"3f700ac5-8519-407a-ce96-4cea9e6943e9"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Feedback: Room was very dated.  Definitely did not meet the expectations I have for a Hyatt\n","property.   Lobby area was nice but rooms were very dated and appeared dirty.   We would not even\n","sit on the couch in the room.\n","Model-Generated Summary: The guest finds the hotel room in a Hyatt property outdated and unsanitary,\n","specifically mentioning the state of the lobby area as acceptable but the condition of the rooms as\n","unacceptable, going as far as avoiding sitting on the provided couches due to their perceived\n","dirtiness.\n","Labeled Sentiment: Negative\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: Had a wonderful stay and would be happy to stay longer if I ever need to.  The\n","facility does show some wear here and there, nothing major or worth specifically calling out.\n","Overall everything for my stay was great\n","Model-Generated Summary: The guest had a positive experience during their stay and appreciated the\n","accommodation. However, minor signs of wear were noticed throughout the facility.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: I'd definitely like to keep booking the same type of room going forward\n","Model-Generated Summary: The individual prefers to continue reserving the same type of room in\n","future bookings.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: My fiancé and I booked the Hyatt in Green Bay, WI, because we had previously\n","stayed at a Hyatt in Chicago, IL-- and loved it. We are very displeased with our stay in at the\n","Hyatt, in WI, and will not be returning.\n","Here are a few things, which have steered our stay to other locations moving forward.\n","1. The room was not clean. We arrived and paid for early check in-- yet got put in a room that had\n","dust all over the place.\n","2. The tv had a burn mark.\n","3. The carpet had a wrinkle in it, between the sliding door and bed, causing me to trip in the\n","middle of the night.\n","4. Went to look in the brochure to find the floor in which the laundry room was, and the brochure\n","appeared to be half eaten by an animal-- therefore we had to call the lobby for them to tell us,\n","what we should have been able to know without calling. That's the whole point of a brochure in a\n","guest room. Very inconvenient.\n","5. The view that we had was horrendous. Opening our curtains, to find we had a beautiful view of the\n","AC units.\n","6. We paid extra for the morning breakfast. Upon arrival, there was no host. We asked a server and\n","she said \"seat yourself, and someone will come get your drinks.\" We did just that. And 10 minutes\n","went by. We had to get up not just once, but twice to get our drinks. That is terrible service and\n","very  unacceptable.\n","\n","Like stated above, we will not be returning to the Hyatt Hotels. The many inconveniences and awful\n","service in the dining area, have made up our mind, that we will in fact take our money elsewhere and\n","stay where we feel we are appreciated.\n","\n","Thank you,\n","\n","Dillon Jones\n","Model-Generated Summary: Dillon Jones shares their negative experience staying at the Hyatt Hotel in\n","Green Bay, Wisconsin. Issues included a dirty room upon early check-in, damaged TV and carpet, lack\n","of information in the brochure, poor view, and poor service during breakfast. As a result, they will\n","not return to Hyatt Hotels and plan to spend their future stays elsewhere.\n","Labeled Sentiment: Very Negative\n","----------------------------------------------------------------------------------------------------\n","Original Feedback: Quality of service was good, but there is always a room for improvement. A smile\n","on their face and saying good morning and good afternoon when ever people approach them it will make\n","it more personal for people to come back an stay at your facility.\n","Model-Generated Summary: Improving customer service by adding personal touches such as greeting\n","guests warmly with a smile and addressing them during their visits could enhance guest experience\n","and encourage repeat visits at the facility.\n","Labeled Sentiment: Very Positive\n","----------------------------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["from tabulate import tabulate\n","\n","data = [\n","    [\"I appreciated the fast check-in and the friendliness of the front desk, but the room was dusty and had a noisy AC.\",\n","     \"Positive service noted; concerns about room cleanliness and noise.\"],\n","\n","    [\"Everything was perfect, from the clean sheets to the excellent breakfast and amazing views.\",\n","     \"Guest expressed full satisfaction with cleanliness, food, and scenery.\"],\n","\n","    [\"Hotel was okay but billing confusion and lack of towels made the stay frustrating.\",\n","     \"Mixed experience; billing issues and missing amenities caused dissatisfaction.\"]\n","]\n","\n","headers = [\"Original Feedback\", \"Model-Generated Summary\"]\n","\n","print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ORrH7GRVSzJ","executionInfo":{"status":"ok","timestamp":1752973052363,"user_tz":300,"elapsed":9,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"18d084a0-1fb4-4b1b-a64a-2c991c4df711"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------------\n","-----------------+--------------------------------------------------------------------------------+\n","| Original Feedback\n","| Model-Generated Summary                                                        |\n","+===================================================================================================\n","=================+================================================================================+\n","| I appreciated the fast check-in and the friendliness of the front desk, but the room was dusty and\n","had a noisy AC. | Positive service noted; concerns about room cleanliness and noise.             |\n","+---------------------------------------------------------------------------------------------------\n","-----------------+--------------------------------------------------------------------------------+\n","| Everything was perfect, from the clean sheets to the excellent breakfast and amazing views.\n","| Guest expressed full satisfaction with cleanliness, food, and scenery.         |\n","+---------------------------------------------------------------------------------------------------\n","-----------------+--------------------------------------------------------------------------------+\n","| Hotel was okay but billing confusion and lack of towels made the stay frustrating.\n","| Mixed experience; billing issues and missing amenities caused dissatisfaction. |\n","+---------------------------------------------------------------------------------------------------\n","-----------------+--------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install reportlab\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaXad329Vsjm","executionInfo":{"status":"ok","timestamp":1752973169994,"user_tz":300,"elapsed":5778,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"4df0d557-88d5-43f5-eee2-40ea035a6879"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting reportlab\n","  Downloading reportlab-4.4.2-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\n","Downloading reportlab-4.4.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: reportlab\n","Successfully installed reportlab-4.4.2\n"]}]},{"cell_type":"code","source":["from reportlab.platypus import SimpleDocTemplate, Table, TableStyle\n","from reportlab.lib import colors\n","\n","data = [\n","    [\"Original Feedback\", \"Model-Generated Summary\"],\n","    [\"I appreciated the fast check-in...\", \"Positive service noted; concerns about room cleanliness and noise.\"],\n","    [\"Everything was perfect...\", \"Guest expressed full satisfaction with cleanliness, food, and scenery.\"],\n","    [\"Hotel was okay but billing confusion...\", \"Mixed experience; billing issues and missing amenities caused dissatisfaction.\"]\n","]\n","\n","output_path = '/content/drive/MyDrive/CAPSTONE/data/summarized_feedback.pdf'\n","pdf = SimpleDocTemplate(output_path)\n","table = Table(data)\n","table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n","    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n","]))\n","pdf.build([table])\n","\n","print(\"✅ PDF saved to Google Drive at:\", output_path)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6bvhBrmVqoC","executionInfo":{"status":"ok","timestamp":1752973250384,"user_tz":300,"elapsed":14,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"c93ab7e0-69ad-4fbc-eb09-4836c25c9235"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ PDF saved to Google Drive at: /content/drive/MyDrive/CAPSTONE/data/summarized_feedback.pdf\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the fine-tuned Hugging Face model and tokenizer\n","model_name = \"philschmid/flan-t5-base-samsum\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","hugging_face__model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n","\n","# Generate summaries using the fine-tuned Hugging Face model\n","def generate_summaries_hf(model, tokenizer, texts):\n","    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","    summaries = model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4, length_penalty=2.0)\n","    decoded_summaries = tokenizer.batch_decode(summaries, skip_special_tokens=True)\n","    return decoded_summaries\n","\n","generated_summaries_hf = generate_summaries_hf(hugging_face__model, tokenizer, texts[:10])\n","\n","for i in range(3):\n","    print(f\"Original Feedback: {test_texts_str[i]}\")\n","    print(f\"LLM Generated Summary {i+1}: {generated_summaries[i]}\")\n","    print(f\"Hugging Face Generated Summary {i+1}: {generated_summaries_hf[i]}\")\n","    print(f\"Few-shot Summary {i+1}: {generated_summaries2[i]}\")\n","    print(f\"Labeled Sentiment {i+1}: {summaries[i]}\")\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTQC1UWD9gTn","executionInfo":{"status":"ok","timestamp":1752971528379,"user_tz":300,"elapsed":5446,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"9ee5691d-1d42-4ed9-80f1-89bc9df8f8f6"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Feedback: Room was very dated.  Definitely did not meet the expectations I have for a Hyatt\n","property.   Lobby area was nice but rooms were very dated and appeared dirty.   We would not even\n","sit on the couch in the room.\n","LLM Generated Summary 1: The guest found the Hyatt property's rooms outdated, unclean, and below\n","their expected standards; they avoided using furniture like the couch due to its condition.\n","Hugging Face Generated Summary 1: Room was very dated. Definitely did not meet the expectations I\n","have for a Hyatt property. Lobby area was nice but rooms were very dated and appeared dirty. We\n","would not even sit on the couch in the room.\n","Few-shot Summary 1: The guest finds the hotel room in a Hyatt property outdated and unsanitary,\n","specifically mentioning the state of the lobby area as acceptable but the condition of the rooms as\n","unacceptable, going as far as avoiding sitting on the provided couches due to their perceived\n","dirtiness.\n","Labeled Sentiment 1: Negative\n","\n","Original Feedback: Had a wonderful stay and would be happy to stay longer if I ever need to.  The\n","facility does show some wear here and there, nothing major or worth specifically calling out.\n","Overall everything for my stay was great\n","LLM Generated Summary 2: Guest had a positive experience with minor cosmetic issues at the facility;\n","they'd return due to overall satisfaction.\n","Hugging Face Generated Summary 2: The room was clean and comfortable. I would stay here again if I\n","ever need to. I would stay here again if I ever need to. I would stay here again if I ever need to.\n","I would stay here again if I ever need to. I would stay here again if I\n","Few-shot Summary 2: The guest had a positive experience during their stay and appreciated the\n","accommodation. However, minor signs of wear were noticed throughout the facility.\n","Labeled Sentiment 2: Very Positive\n","\n","Original Feedback: I'd definitely like to keep booking the same type of room going forward\n","LLM Generated Summary 3: The user prefers to continue reserving the same room type for future\n","bookings.\n","Hugging Face Generated Summary 3: I'd like to keep booking the same type of room going forward. I'd\n","definitely like to keep booking the same type of room going forward. I'd like to keep booking the\n","same type of room going forward. I'd definitely like to keep booking the same type of room going\n","forward.\n","Few-shot Summary 3: The individual prefers to continue reserving the same type of room in future\n","bookings.\n","Labeled Sentiment 3: Very Positive\n","\n"]}]},{"cell_type":"code","source":["# 1. Load and rename your dataset\n","import pandas as pd\n","from datasets import Dataset\n","\n","df = pd.read_csv('/content/drive/MyDrive/CAPSTONE/data/Hyatt_LTR_Sentiment.csv')\n","df = df[['Additional.Feedback.on.Overall.Stay', 'Sentiment']].dropna()\n","df = df.rename(columns={\n","    \"Additional.Feedback.on.Overall.Stay\": \"text\",\n","    \"Sentiment\": \"summary\"\n","})\n","\n","# 2. Convert to Hugging Face Dataset and split\n","dataset = Dataset.from_pandas(df)\n","dataset = dataset.train_test_split(test_size=0.2)\n","eval_dataset = dataset[\"test\"]\n","\n","# 3. Load tokenizer and model\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_name = \"philschmid/flan-t5-base-samsum\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","hugging_face__model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","# 4. Tokenize the dataset\n","def preprocess_function(examples):\n","    model_inputs = tokenizer(examples[\"text\"], max_length=512, truncation=True, padding=\"max_length\")\n","    labels = tokenizer(text_target=examples[\"summary\"], max_length=64, truncation=True, padding=\"max_length\")\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_dataset = eval_dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=[\"text\", \"summary\", \"__index_level_0__\"]\n",")\n","\n","# ✅ 5. Select a smaller subset to avoid OOM\n","small_eval_dataset = tokenized_dataset.select(range(100))  # You can reduce to 50 or 20 if needed\n","\n","# 6. Define data collator\n","from transformers import DataCollatorForSeq2Seq\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=hugging_face__model)\n","\n","# 7. Define compute_metrics\n","from evaluate import load\n","from nltk import sent_tokenize, download\n","import numpy as np\n","import warnings\n","\n","download(\"punkt\", quiet=True)\n","rouge = load(\"rouge\")\n","bertscore = load(\"bertscore\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    if isinstance(predictions, tuple):\n","        predictions = predictions[0]\n","    predictions = np.asarray(predictions)\n","    labels = np.asarray(labels)\n","    if predictions.ndim == 3:\n","        predictions = np.argmax(predictions, axis=-1)\n","    predictions = predictions.tolist()\n","    labels = labels.tolist()\n","    pad_token_id = tokenizer.pad_token_id\n","    labels = [[(token if token != -100 else pad_token_id) for token in label] for label in labels]\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n","    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    rouge_result = {f\"{k}_f1\": v * 100 for k, v in rouge_scores.items()}\n","    with warnings.catch_warnings():\n","        warnings.simplefilter(\"ignore\")\n","        bertscore_result = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n","    bertscore_f1 = {\"bertscore_f1\": np.mean(bertscore_result[\"f1\"]) * 100}\n","    return {**rouge_result, **bertscore_f1}\n","\n","# 8. Define evaluation function\n","from transformers import TrainingArguments, Trainer\n","\n","def evaluate_metrics(model, dataset, data_collator, compute_metrics):\n","    training_args = TrainingArguments(\n","        output_dir=\"./results\",\n","        per_device_eval_batch_size=1,  # Keep it small to avoid OOM\n","        remove_unused_columns=False\n","    )\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        eval_dataset=dataset,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )\n","    return trainer.evaluate()\n","\n","# ✅ Disable wandb logging to avoid API key issues\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# ✅ Clear GPU memory before evaluation\n","import torch\n","torch.cuda.empty_cache()\n","\n","# ✅ Run evaluation on the smaller subset\n","fine_tuned_results = evaluate_metrics(hugging_face__model, small_eval_dataset, data_collator, compute_metrics)\n","print(\"\\n📈 Fine-Tuned Model Results (Subset of 100):\")\n","print(fine_tuned_results)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197,"referenced_widgets":["80b757ec8a95404eb644981847c4e4ff","f4cefe4c35844e4fb4915c8dab09fa4e","e9859c2a953b479d98f97c54da2c499a","77a30748d1db42d49acba426b58f1efe","5665ef0fb79342ceaf0ca207aaa390b1","ebf8642ab1bc4fb886801b331fa95130","ddcba0896f5f41de9046cb071d293956","5d9b72c899ca4b4b98b97a20eb980ad7","21d2966dcd4b4611b5ba272a32f1f502","8c986f9f4aba411f86328acbd0b56f6a","02ca70270a57402c82a0e5f96e7e767a"]},"id":"0DICJBuBDa_S","executionInfo":{"status":"ok","timestamp":1752971547436,"user_tz":300,"elapsed":17235,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"34fad886-61b0-41b1-c6fb-612d5843f23f"},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1336 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b757ec8a95404eb644981847c4e4ff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 45.66122055053711, 'eval_model_preparation_time': 0.0058, 'eval_rouge1_f1': 0.15861106107007747, 'eval_rouge2_f1': 0.0, 'eval_rougeL_f1': 0.1584279108869273, 'eval_rougeLsum_f1': 0.15940471186372826, 'eval_bertscore_f1': 71.25017684698105, 'eval_runtime': 14.7449, 'eval_samples_per_second': 6.782, 'eval_steps_per_second': 6.782}\n","\n","📈 Fine-Tuned Model Results (Subset of 100):\n","{'eval_loss': 45.66122055053711, 'eval_model_preparation_time': 0.0058, 'eval_rouge1_f1':\n","0.15861106107007747, 'eval_rouge2_f1': 0.0, 'eval_rougeL_f1': 0.1584279108869273,\n","'eval_rougeLsum_f1': 0.15940471186372826, 'eval_bertscore_f1': 71.25017684698105, 'eval_runtime':\n","14.7449, 'eval_samples_per_second': 6.782, 'eval_steps_per_second': 6.782}\n"]}]},{"cell_type":"code","source":["eval_results = {\n","    'eval_loss': 45.66122055053711,\n","    'eval_model_preparation_time': 0.0058,\n","    'eval_rouge1_f1': 0.15861106107007747,\n","    'eval_rouge2_f1': 0.0,\n","    'eval_rougeL_f1': 0.1584279108869273,\n","    'eval_rougeLsum_f1': 0.15940471186372826,\n","    'eval_bertscore_f1': 71.25017684698105,\n","    'eval_runtime': 14.7449,\n","    'eval_samples_per_second': 6.782,\n","    'eval_steps_per_second': 6.782\n","}\n","results_df = pd.DataFrame([eval_results])\n","print(results_df)\n","results_df.to_csv('/content/drive/MyDrive/CAPSTONE/data/eval_metrics_table.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bE36uULhXDhs","executionInfo":{"status":"ok","timestamp":1752973469060,"user_tz":300,"elapsed":14,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"000ed5e2-40dc-412b-ef31-40b8112d94ae"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["   eval_loss  eval_model_preparation_time  eval_rouge1_f1  eval_rouge2_f1  \\\n","0  45.661221                       0.0058        0.158611             0.0\n","\n","   eval_rougeL_f1  eval_rougeLsum_f1  eval_bertscore_f1  eval_runtime  \\\n","0        0.158428           0.159405          71.250177       14.7449\n","\n","   eval_samples_per_second  eval_steps_per_second\n","0                    6.782                  6.782\n"]}]},{"cell_type":"code","source":["from reportlab.platypus import SimpleDocTemplate, Table, TableStyle\n","from reportlab.lib import colors\n","\n","# Define your metrics\n","eval_results = {\n","    'eval_loss': 45.6612,\n","    'eval_model_preparation_time': 0.0058,\n","    'eval_rouge1_f1': 0.1586,\n","    'eval_rouge2_f1': 0.0,\n","    'eval_rougeL_f1': 0.1584,\n","    'eval_rougeLsum_f1': 0.1594,\n","    'eval_bertscore_f1': 71.2502,\n","    'eval_runtime': 14.7449,\n","    'eval_samples_per_second': 6.782,\n","    'eval_steps_per_second': 6.782\n","}\n","\n","# Convert to table format\n","table_data = [[\"Metric\", \"Value\"]] + [[k, f\"{v:.4f}\"] for k, v in eval_results.items()]\n","\n","# Set output path\n","output_path = \"/content/drive/MyDrive/CAPSTONE/data/eval_metrics.pdf\"\n","\n","# Create PDF\n","pdf = SimpleDocTemplate(output_path)\n","table = Table(table_data)\n","table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n","    ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","\n","pdf.build([table])\n","print(\"✅ PDF saved to:\", output_path)\n"],"metadata":{"id":"L5mOOJJXXjKu","executionInfo":{"status":"ok","timestamp":1752973609068,"user_tz":300,"elapsed":44,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"38010a62-98fc-4f38-d3f0-5d8fa2ca17eb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ PDF saved to: /content/drive/MyDrive/CAPSTONE/data/eval_metrics.pdf\n"]}]},{"cell_type":"code","source":["import json\n","\n","# Load from JSON\n","with open(\"generated_summaries_llm.json\", \"r\") as f:\n","    generated_summaries2 = json.load(f)\n","\n","print(\"✅ Summaries loaded from file\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OE_X-dIDULdX","executionInfo":{"status":"ok","timestamp":1752971558975,"user_tz":300,"elapsed":26,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"5a3803f6-695a-4c05-e434-05cd95d4b256"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Summaries loaded from file\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df_results = pd.DataFrame({\n","    \"Original_Feedback\": texts,\n","    \"Generated_Summary\": generated_summaries2,\n","    \"Labeled_Sentiment\": summaries\n","})\n","\n","df_results.to_csv(\"/content/drive/MyDrive/CAPSTONE/data/llm_summary_results.csv\", index=False)\n","print(\"✅ Full results saved to llm_summary_results.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlHkHr0SYudV","executionInfo":{"status":"ok","timestamp":1752971561235,"user_tz":300,"elapsed":22,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"75861d51-2ba3-4b0f-fb6a-d50dd8790ee9"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Full results saved to llm_summary_results.csv\n"]}]},{"cell_type":"code","source":["def extract_theme(summary):\n","    prompt = (\n","        f\"Extract a 1–2 word theme that best captures the core idea of this summary:\\n\\n\"\n","        f\"Summary: {summary}\\n\\n\"\n","        f\"Respond with only the theme, no punctuation or extra words.\"\n","    )\n","    response = llm_generate(llm_config, [prompt], system_prompt=\"You are a helpful theme extractor.\")\n","    return response[0].strip().lower()\n","\n","\n","import pandas as pd\n","\n","themes = [extract_theme(summary) for summary in generated_summaries2]"],"metadata":{"id":"bKp3Zi3COLwt","executionInfo":{"status":"ok","timestamp":1752971723881,"user_tz":300,"elapsed":158678,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["theme_df = pd.DataFrame({\n","    \"Sentiment\": test_summaries_str[:100],\n","    \"Theme\": themes,\n","    \"Summary\": generated_summaries2\n","})\n","\n","# Get top 6 most frequent themes per sentiment\n","top_themes = (\n","    theme_df.groupby(\"Sentiment\")[\"Theme\"]\n","    .value_counts()\n","    .groupby(level=0)\n","    .head(6)\n","    .reset_index(name=\"Count\")\n",")\n","# Pivot into a 6-column format, padding with NaN if fewer than 6 themes\n","theme_table = top_themes.groupby(\"Sentiment\").apply(\n","    lambda x: pd.Series(\n","        list(x[\"Theme\"].values[:6]) + [None] * (6 - len(x[\"Theme\"].values[:6])),\n","        index=[f\"Theme {i+1}\" for i in range(6)]\n","    )\n",").reset_index()\n","\n","print(theme_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZ41dCcfY-Or","executionInfo":{"status":"ok","timestamp":1752971736854,"user_tz":300,"elapsed":27,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"78761913-4a03-4fb5-99b5-7ad1a1a01e50"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["               Sentiment                    Theme 1  \\\n","0       Mixed or Neutral              deterioration\n","1               Negative  dissatisfied (experience)\n","2  Positive but Critical               poor service\n","3      Slightly Negative     comfortable-slowdrains\n","4          Very Negative           collision/damage\n","5          Very Positive             disappointment\n","\n","                                           Theme 2  \\\n","0  discomfort/inconvenience (heating/food quality)\n","1                  frustration, aroma, recognition\n","2                             accommodation issues\n","3                                            dirty\n","4                                   disappointment\n","5                           adjacent rooms (noise)\n","\n","                                             Theme 3  \\\n","0                                lack (of) hot water\n","1                                         overcharge\n","2                               children-restriction\n","3  disappointment (core emotion) or continental b...\n","4                     dissatisfaction (with service)\n","5                                     awesome (team)\n","\n","                                          Theme 4  \\\n","0                                 parking, access\n","1                            unsanitary/dirtiness\n","2                          costly/average quality\n","3                                     fees, costs\n","4                 dissatisfied service/facilities\n","5  cleanliness (pool area), food options (snacks)\n","\n","                                     Theme 5  \\\n","0                                       rush\n","1                                       None\n","2                       difficulty (parking)\n","3                              inconvenience\n","4  full (parking lot) / unavailable (spaces)\n","5        coffee (decaffeinated unexpectedly)\n","\n","                                Theme 6\n","0         unreasonablefee / poorservice\n","1                                  None\n","2      dissatisfaction (with breakfast)\n","3  late/cleanliness/mishandled services\n","4             hotel (heating/breakfast)\n","5                               comfort\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-74-576579624.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  theme_table = top_themes.groupby(\"Sentiment\").apply(\n"]}]},{"cell_type":"code","source":["min_len = min(len(test_summaries_str[:100]), len(themes), len(generated_summaries2))\n","\n","theme_df = pd.DataFrame({\n","    \"Sentiment\": test_summaries_str[:min_len],\n","    \"Theme\": themes[:min_len],\n","    \"Summary\": generated_summaries2[:min_len]\n","})\n"],"metadata":{"id":"7DhFtH1PMzyk","executionInfo":{"status":"ok","timestamp":1752971739977,"user_tz":300,"elapsed":45,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["# Save the 6-column theme table to CSV\n","theme_table.to_csv(\"top_themes_by_sentiment.csv\", index=False)\n","print(\"✅ Saved theme table to top_themes_by_sentiment.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HM79Xi98aD8k","executionInfo":{"status":"ok","timestamp":1752971741666,"user_tz":300,"elapsed":9,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"09aa5f0e-d9f0-4cd6-b57e-e4804c7b2d5e"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Saved theme table to top_themes_by_sentiment.csv\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import matplotlib.pyplot as plt\n","# Save CSV to your Drive\n","theme_table.to_csv(\"/content/drive/MyDrive/CAPSTONE/data/top_themes_by_sentiment.csv\", index=False)\n","\n","# Save chart to your Drive\n","plt.savefig(\"/content/drive/MyDrive/CAPSTONE/data/top_themes_bar_chart.png\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"q2bO5j3oalFk","executionInfo":{"status":"ok","timestamp":1752971746435,"user_tz":300,"elapsed":872,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"530d2f1d-1aff-4c08-9f90-dedc29360219"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["def validate_theme_sentiment(theme, sentiment):\n","    prompt = (\n","        f\"Does the theme '{theme}' align with the sentiment '{sentiment}'?\\n\"\n","        f\"Respond with 'yes' or 'no'.\"\n","    )\n","    response = llm_generate(llm_config, [prompt], system_prompt=\"You are a helpful sentiment validator.\")\n","    return response[0].strip().lower() == \"yes\"\n"],"metadata":{"id":"m07vfRwBbnyY","executionInfo":{"status":"ok","timestamp":1752971784602,"user_tz":300,"elapsed":43,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["# Melt the theme table to long format for validation\n","theme_long = theme_table.melt(id_vars=\"Sentiment\", var_name=\"Theme_Rank\", value_name=\"Theme\")\n","\n","# Drop NaNs\n","theme_long = theme_long.dropna(subset=[\"Theme\"])\n","\n","# Validate each theme\n","theme_long[\"Valid\"] = theme_long.apply(\n","    lambda row: validate_theme_sentiment(row[\"Theme\"], row[\"Sentiment\"]), axis=1\n",")\n","\n","# Keep only valid themes\n","theme_long_filtered = theme_long[theme_long[\"Valid\"]]\n","\n","# Pivot back to wide format\n","theme_table_filtered = (\n","    theme_long_filtered\n","    .groupby(\"Sentiment\")[\"Theme\"]\n","    .apply(lambda x: pd.Series(x.values[:6], index=[f\"Theme {i+1}\" for i in range(len(x[:6]))]))\n","    .reset_index()\n",")\n","\n","print(theme_table_filtered)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUZeJodHbpXq","executionInfo":{"status":"ok","timestamp":1752972060283,"user_tz":300,"elapsed":273969,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"5a74760d-c63f-4807-991e-c6000827263d"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["                Sentiment  level_1  \\\n","0        Mixed or Neutral  Theme 1\n","1        Mixed or Neutral  Theme 2\n","2        Mixed or Neutral  Theme 3\n","3                Negative  Theme 1\n","4                Negative  Theme 2\n","5                Negative  Theme 3\n","6                Negative  Theme 4\n","7   Positive but Critical  Theme 1\n","8       Slightly Negative  Theme 1\n","9       Slightly Negative  Theme 2\n","10      Slightly Negative  Theme 3\n","11      Slightly Negative  Theme 4\n","12      Slightly Negative  Theme 5\n","13          Very Negative  Theme 1\n","14          Very Negative  Theme 2\n","15          Very Negative  Theme 3\n","16          Very Positive  Theme 1\n","\n","                                                Theme\n","0                                       deterioration\n","1                                     parking, access\n","2                       unreasonablefee / poorservice\n","3                           dissatisfied (experience)\n","4                     frustration, aroma, recognition\n","5                                          overcharge\n","6                                unsanitary/dirtiness\n","7                                difficulty (parking)\n","8                                               dirty\n","9   disappointment (core emotion) or continental b...\n","10                                        fees, costs\n","11                                      inconvenience\n","12               late/cleanliness/mishandled services\n","13                                     disappointment\n","14                     dissatisfaction (with service)\n","15          full (parking lot) / unavailable (spaces)\n","16                                     awesome (team)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","theme_table_filtered.to_csv(\"theme_table_filtered.csv\", index=False)\n","print(\"✅ Saved theme table to top_themes_by_sentiment.csv\")\n","# Save CSV to your Drive\n","theme_table_filtered.to_csv(\"/content/drive/MyDrive/CAPSTONE/data/theme_table_filtered.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltflM1cBdLwS","executionInfo":{"status":"ok","timestamp":1752972068074,"user_tz":300,"elapsed":550,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"8f761938-5bae-4b79-ba87-a98d67858e98"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Saved theme table to top_themes_by_sentiment.csv\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Load sentiment analysis pipeline\n","sentiment_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n"],"metadata":{"id":"cQChLNHseF3O","executionInfo":{"status":"ok","timestamp":1752972071636,"user_tz":300,"elapsed":379,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["def simplify_sentiment(label):\n","    label = label.lower()\n","    if \"positive\" in label:\n","        return \"POSITIVE\"\n","    elif \"negative\" in label:\n","        return \"NEGATIVE\"\n","    else:\n","        return \"NEUTRAL\"\n"],"metadata":{"id":"QApITht0eH96","executionInfo":{"status":"ok","timestamp":1752972074333,"user_tz":300,"elapsed":9,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["# Melt the theme table to long format\n","theme_long = theme_table.melt(id_vars=\"Sentiment\", var_name=\"Theme_Rank\", value_name=\"Theme\")\n","theme_long = theme_long.dropna(subset=[\"Theme\"])\n","\n","# Simplify sentiment labels\n","theme_long[\"Simplified_Sentiment\"] = theme_long[\"Sentiment\"].apply(simplify_sentiment)\n","\n","# Classify each theme\n","theme_long[\"Predicted_Sentiment\"] = theme_long[\"Theme\"].apply(\n","    lambda x: sentiment_classifier(x)[0][\"label\"]\n",")\n","\n","# Compare predicted vs labeled\n","theme_long[\"Valid\"] = theme_long[\"Simplified_Sentiment\"] == theme_long[\"Predicted_Sentiment\"]\n"],"metadata":{"id":"aIZK1YtieI93","executionInfo":{"status":"ok","timestamp":1752972077242,"user_tz":300,"elapsed":280,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["# Keep only valid themes\n","theme_long_filtered = theme_long[theme_long[\"Valid\"]]\n","\n","# Pivot back to wide format\n","theme_table_filtered2 = (\n","    theme_long_filtered\n","    .groupby(\"Sentiment\")[\"Theme\"]\n","    .apply(lambda x: pd.Series(x.values[:6], index=[f\"Theme {i+1}\" for i in range(len(x[:6]))]))\n","    .reset_index()\n",")\n","\n","# Save to Drive\n","theme_table_filtered2.to_csv(\"/content/drive/MyDrive/CAPSTONE/data/filtered_theme_table2.csv\", index=False)\n","print(\"✅ Saved filtered theme table to Drive\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cjoq34tAeJ2Y","executionInfo":{"status":"ok","timestamp":1752972080524,"user_tz":300,"elapsed":239,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"260d7490-94a7-4dc2-c592-0b24cb9e7178"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Saved filtered theme table to Drive\n"]}]},{"cell_type":"code","source":["!pip install tabulate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04XDTRO9SPtX","executionInfo":{"status":"ok","timestamp":1752972211889,"user_tz":300,"elapsed":4746,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"24c83f7d-92a9-49fb-ec36-706f82e5e199"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"]}]},{"cell_type":"code","source":["from tabulate import tabulate\n","\n","print(tabulate(theme_table_filtered2, headers='keys', tablefmt='psql'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGM7-8UKST0A","executionInfo":{"status":"ok","timestamp":1752972330243,"user_tz":300,"elapsed":25,"user":{"displayName":"Isaac Caelwaerts","userId":"03589605664018462324"}},"outputId":"dce6e864-42d0-4e15-bf6e-60a3c41d4a4c"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------------+-----------+--------------------------------------------------------------\n","--+\n","|    | Sentiment         | level_1   | Theme\n","|\n","|----+-------------------+-----------+--------------------------------------------------------------\n","--|\n","|  0 | Negative          | Theme 1   | dissatisfied (experience)\n","|\n","|  1 | Negative          | Theme 2   | frustration, aroma, recognition\n","|\n","|  2 | Negative          | Theme 3   | overcharge\n","|\n","|  3 | Negative          | Theme 4   | unsanitary/dirtiness\n","|\n","|  4 | Slightly Negative | Theme 1   | dirty\n","|\n","|  5 | Slightly Negative | Theme 2   | disappointment (core emotion) or continental breakfast\n","(topic) |\n","|  6 | Slightly Negative | Theme 3   | inconvenience\n","|\n","|  7 | Slightly Negative | Theme 4   | late/cleanliness/mishandled services\n","|\n","|  8 | Very Negative     | Theme 1   | collision/damage\n","|\n","|  9 | Very Negative     | Theme 2   | disappointment\n","|\n","| 10 | Very Negative     | Theme 3   | dissatisfaction (with service)\n","|\n","| 11 | Very Negative     | Theme 4   | dissatisfied service/facilities\n","|\n","| 12 | Very Negative     | Theme 5   | full (parking lot) / unavailable (spaces)\n","|\n","| 13 | Very Positive     | Theme 1   | awesome (team)\n","|\n","| 14 | Very Positive     | Theme 2   | cleanliness (pool area), food options (snacks)\n","|\n","| 15 | Very Positive     | Theme 3   | comfort\n","|\n","+----+-------------------+-----------+--------------------------------------------------------------\n","--+\n"]}]}]}